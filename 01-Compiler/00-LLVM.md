# LLVM介绍

摘自LLVM项目的创始者Chris Lattner的介绍：[The Architecture of Open Source Applications: LLVM](http://www.aosabook.org/en/llvm.html)

### 什么是LLVM？
LLVM是一种编译器基础设施，以C++写成，包含一系列模块化的编译器组件和工具链，用来开发编译器前端和后端。它与其他编译器的主要不同在于内部采用的架构。

### LLVM产生的背景
在2000年前，开源的语言执行工具工呈现两级分化：要么是传统的静态编译器，例如GCC、Free Pascal、FreeBASIC，是一种较为庞大的执行工具，很难重用这些静态编译器的的语法分析器(parser)作为静态分析或者重构；另外一种则以解释器或者Just-In-Time (JIT) compiler的方式提供动态编译。但很少有语言实现工具可以同时支持这两种，即使有也很少开源。

LLVM的提出就是为了改变这样的情况，LLVM现在被广泛用作一种常见的基础架构用来实现大量的不同语言的动态或者静态编译器(例如GCC, Java, .NET, python, Ruby, Scheme, Haskell等等)。此外，LLVM还取代了大量的用于特殊目的的编译器，例如Apple的OpenGL Stack中的动态专门化引擎以及Adobe产品中的图像处理库。LLVM还被用于创建大量的新产品，最著名的是用于OpenCL GPU编程语言和runtime。

### 传统经典编译器的简单介绍

最常见的对传统静态语言编译器（例如大部分的C编译器）一般采用的是三段设计：前端、优化器、后段，参考下图。前端用于解析用户输入的源码，检查错误，建立特定语言的抽象语法树([Abstract Syntax Tree, AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree))用于表示输入代码。AST可以选择性的转换为用于优化的新代码，优化器和后段会作用于这个代码。
![三段设计](Pictures/SimpleCompiler.png)

优化器一般会做大量的转换用于提高代码的实时性，例如减少不必要的计算，它多多少少是独立于语言和生成目标饿。后端（也被称为代码生成器，code generator）将代码映射到目标架构的指令集上。后端需要尽可能生成处能够利用目标架构的特殊优势的良好代码。编译器后端一般包括指令选择，寄存器分配和指令时序分配等。

这个三段模型通用适用于动态解释器和JIT编译器。Java虚拟机([Java Virtual Machine, JVM](https://en.wikipedia.org/wiki/Java_virtual_machine))也是这种模型的一种是心啊，其中Java bytecode用于前端和优化器的中间连接。

#### 三段式设计的优势
这种经典的传统三段式设计方法最大的优势在于编译器可以支持多种语言和架构。如果编译器使用一种常见的编码作为优化器的表征，那么前端可以采用任意的编程语言，后端可以作用于任意的目标架构，参见下图。
![RetargetableCompiler](Pictures/RetargetableCompiler.png)

在这种设计下，如果编译器要支持一种新的语言(例如BASIC)需要重新实现一个新的前端，但是当前的优化器和后端可以被重新使用。如果不采用这种三段模式，那么这些部分就无法被分割，实现一个对新编程语言的执行就需要从头做起，需要支持N个目标架构和M种编程语言将会需要N乘M个编译器。

另一个三段式设计方法的优点在于编译器可以服务于采用不同编程语言的各类程序员。对于一个开源项目来说，这意味着这将会有一个更大的群体和更多的贡献，能够进一步提高和增强现有的编译器。这也是为什么一些开源编译器服务于许多社区(例如GCC)都在尝试生成更好的机器码而不是单一化编译器(例如FreePASCAL)。

最后一个优点是这种分割方式能让前后端的开发人员很好的维护和增进自己的部分，属于松耦合。对于开源软件来说，松耦合可以帮助减少其他人员开发时的障碍。

### 现有编程语言的实现

尽管三段式设计的优势巨大，但在实际中基本不可能被完全实现。回顾从LLVM之前的开源语言实现，你会发现对Perl,Python,Ruby和Java的实现没有共享任何代码。更进一步，Glasgow Haskeel COmpiler (GHC)和FreeBASIC等项目可以重映射在不同的CPU上，但他们只能支持一种编程语言。

之前提到过，这里有三种成功实现了这种模型，第一种是个Java和.NET虚拟机。他们的系统提供了一种JIT编译器，支持runtime和一种定义好的bytecode格式。这意味着任何语言都可以编译成bytecode的格式并且在运行时利用优化器和JIT的优势。作为代价的是，这些实现基本无法提供对runtime的选择上的灵活性：他们都采用JIT编译，垃圾回收和专门的面向对象模型。这导致了当编译的语言不是很符合该模型时（例如C）只有部分优化后的性能。

另一个成功的案例可以说是最不幸的，但是也是一种重新使用编译器技术的常见方式：将输入的源代码翻译成C代码然后送入已有的C代码编译器。这允许重新使用优化器和代码生成器，有很好的灵活性来控制runtime，这种方式也非常方便前端执行者理解和维护。但不幸的是，采用这种方式会阻止有效的异常处理的实现，并且只提供了非常糟糕的debug过程，减慢了编译速度，并且当新的语言想要加入其他特点（C语言没有的）时容易出现问题。

最后一个对三段式模型的成功实现是[GCC](https://en.wikipedia.org/wiki/GNU_Compiler_Collection)。GCC支持许多的前端和后端，并且有非常活跃和广泛的社区贡献者。GCC有一段很长的成为C编译器的历史，并且支持了多种架构，一些其他语言也依赖于GCC。渐渐的，GCC社区慢慢衍化出了一个更清晰的设计。GCC4.4，拥有一种对优化器的新的表示方式，与提到的三段式模型更加接近。

尽管上述三个案例都非常成功，但这三个方式都拥有非常大的使用局限性，因为他们被设计用于单个且庞大的应用。举个例子，现实中将GCC嵌入到其他应用，比如将GCC用作一个runtime/JIT编译器或者提取并重新使用GCC中的一部分基本是不可能的。想要使用GCC中C++的前端用于文件生成、重构、静态分析工具的开发者不得不将GCC用作一个巨大单一的应用来实现他们的想法，即很难抽取GCC中一部分用作他用。

这里有一些对GCC为什么很难被重新用做库的解释，包括GCC中对全局变量的滥用，没有仔细设计的数据结构，宏的应用等。最难以修复的问题是它最早被设计时产生的内部架构的问题。具体来说，GCC存在layering和抽象泄露(leaky abstractions)的问题：后端需要使用前端的AST来生成debug信息，而前端生成了后端的数据结构，因此整个编译器以来于许多全局结构。

总结：三段式设计有重要的优势，但现实中三种成功实现并没有完全达到当初的目标。其中，GCC已经拥有了尽可能的前后端分离模式的设计，但依然存在前后端的大量耦合，因此给其他开发者的重用带来了极大的不便。